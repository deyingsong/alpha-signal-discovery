{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Feature Engineering\n",
    "## Advanced Feature Creation for Trading Strategy\n",
    "\n",
    "This notebook implements comprehensive feature engineering techniques to enhance predictive power.\n",
    "\n",
    "### Objectives:\n",
    "1. Create temporal features (lags, rolling statistics)\n",
    "2. Generate interaction and polynomial features\n",
    "3. Implement technical indicators\n",
    "4. Apply dimensionality reduction techniques\n",
    "5. Perform feature selection and importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Prepare Base Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data from previous notebook\n",
    "df = pd.read_csv('./data/processed/clean_data.csv')\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "signal_cols = [f'F{i}' for i in range(1, 11)]\n",
    "X_base = df[signal_cols].copy()\n",
    "y = df['Returns'].copy()\n",
    "\n",
    "# Important: Align features with next-day returns (prevent lookahead bias)\n",
    "X_base = X_base.iloc[:-1]  # Remove last row of features\n",
    "y = y.iloc[1:].reset_index(drop=True)  # Shift returns forward by 1 day\n",
    "\n",
    "print(f\"\\nAligned shapes:\")\n",
    "print(f\"Features: {X_base.shape}\")\n",
    "print(f\"Target: {y.shape}\")\n",
    "print(f\"\\nBase features: {list(X_base.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Features (Lags and Rolling Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(X, lags=[1, 2, 3, 5, 10, 20]):\n",
    "    \"\"\"Create lagged versions of features.\"\"\"\n",
    "    X_lagged = X.copy()\n",
    "    \n",
    "    for lag in lags:\n",
    "        for col in X.columns:\n",
    "            X_lagged[f'{col}_lag{lag}'] = X[col].shift(lag)\n",
    "    \n",
    "    return X_lagged\n",
    "\n",
    "def create_rolling_features(X, windows=[5, 10, 20, 50]):\n",
    "    \"\"\"Create rolling statistics features.\"\"\"\n",
    "    X_rolling = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    for window in windows:\n",
    "        for col in X.columns:\n",
    "            # Rolling mean\n",
    "            X_rolling[f'{col}_roll_mean_{window}'] = X[col].rolling(window=window).mean()\n",
    "            # Rolling std\n",
    "            X_rolling[f'{col}_roll_std_{window}'] = X[col].rolling(window=window).std()\n",
    "            # Rolling min/max\n",
    "            X_rolling[f'{col}_roll_min_{window}'] = X[col].rolling(window=window).min()\n",
    "            X_rolling[f'{col}_roll_max_{window}'] = X[col].rolling(window=window).max()\n",
    "            # Rolling skewness\n",
    "            X_rolling[f'{col}_roll_skew_{window}'] = X[col].rolling(window=window).skew()\n",
    "    \n",
    "    return X_rolling\n",
    "\n",
    "def create_momentum_features(X, periods=[5, 10, 20]):\n",
    "    \"\"\"Create momentum and rate of change features.\"\"\"\n",
    "    X_momentum = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    for period in periods:\n",
    "        for col in X.columns:\n",
    "            # Simple momentum\n",
    "            X_momentum[f'{col}_momentum_{period}'] = X[col] - X[col].shift(period)\n",
    "            # Rate of change\n",
    "            X_momentum[f'{col}_roc_{period}'] = (X[col] / X[col].shift(period) - 1)\n",
    "    \n",
    "    return X_momentum\n",
    "\n",
    "# Create temporal features\n",
    "print(\"Creating temporal features...\")\n",
    "X_lagged = create_lagged_features(X_base)\n",
    "X_rolling = create_rolling_features(X_base)\n",
    "X_momentum = create_momentum_features(X_base)\n",
    "\n",
    "# Combine temporal features\n",
    "X_temporal = pd.concat([X_base, X_lagged, X_rolling, X_momentum], axis=1)\n",
    "\n",
    "print(f\"Temporal features created:\")\n",
    "print(f\"  Lagged features: {len(X_lagged.columns) - len(X_base.columns)}\")\n",
    "print(f\"  Rolling features: {len(X_rolling.columns)}\")\n",
    "print(f\"  Momentum features: {len(X_momentum.columns)}\")\n",
    "print(f\"  Total temporal features: {len(X_temporal.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Non-Linear Features (Interactions and Polynomials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_features(X, max_features=10):\n",
    "    \"\"\"Create pairwise interaction features for top features.\"\"\"\n",
    "    X_interactions = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    # Use only base features for interactions to avoid explosion\n",
    "    base_cols = [col for col in X.columns if not any(x in col for x in ['lag', 'roll', 'momentum', 'roc'])]\n",
    "    base_cols = base_cols[:max_features]  # Limit to top features\n",
    "    \n",
    "    for col1, col2 in combinations(base_cols, 2):\n",
    "        X_interactions[f'{col1}_x_{col2}'] = X[col1] * X[col2]\n",
    "    \n",
    "    return X_interactions\n",
    "\n",
    "def create_polynomial_features(X, degree=2, max_features=10):\n",
    "    \"\"\"Create polynomial features.\"\"\"\n",
    "    X_poly = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    # Use only base features\n",
    "    base_cols = [col for col in X.columns if not any(x in col for x in ['lag', 'roll', 'momentum', 'roc'])]\n",
    "    base_cols = base_cols[:max_features]\n",
    "    \n",
    "    for col in base_cols:\n",
    "        for d in range(2, degree + 1):\n",
    "            X_poly[f'{col}_pow{d}'] = X[col] ** d\n",
    "    \n",
    "    # Add ratios\n",
    "    for col1, col2 in combinations(base_cols[:5], 2):  # Limit ratios to top 5 features\n",
    "        X_poly[f'{col1}_div_{col2}'] = X[col1] / (X[col2] + 1e-10)  # Add small constant to avoid division by zero\n",
    "    \n",
    "    return X_poly\n",
    "\n",
    "def create_trigonometric_features(X, max_features=5):\n",
    "    \"\"\"Create trigonometric transformations.\"\"\"\n",
    "    X_trig = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    base_cols = [col for col in X.columns if not any(x in col for x in ['lag', 'roll', 'momentum', 'roc'])]\n",
    "    base_cols = base_cols[:max_features]\n",
    "    \n",
    "    for col in base_cols:\n",
    "        # Normalize to [-π, π] range\n",
    "        normalized = 2 * np.pi * (X[col] - X[col].min()) / (X[col].max() - X[col].min() + 1e-10) - np.pi\n",
    "        X_trig[f'{col}_sin'] = np.sin(normalized)\n",
    "        X_trig[f'{col}_cos'] = np.cos(normalized)\n",
    "    \n",
    "    return X_trig\n",
    "\n",
    "# Create non-linear features\n",
    "print(\"Creating non-linear features...\")\n",
    "X_interactions = create_interaction_features(X_base)\n",
    "X_polynomial = create_polynomial_features(X_base)\n",
    "X_trig = create_trigonometric_features(X_base)\n",
    "\n",
    "# Combine all non-linear features\n",
    "X_nonlinear = pd.concat([X_interactions, X_polynomial, X_trig], axis=1)\n",
    "\n",
    "print(f\"Non-linear features created:\")\n",
    "print(f\"  Interaction features: {len(X_interactions.columns)}\")\n",
    "print(f\"  Polynomial features: {len(X_polynomial.columns)}\")\n",
    "print(f\"  Trigonometric features: {len(X_trig.columns)}\")\n",
    "print(f\"  Total non-linear features: {len(X_nonlinear.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_technical_indicators(X, returns):\n",
    "    \"\"\"Create technical indicators based on signals and returns.\"\"\"\n",
    "    X_tech = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    # Create cumulative returns for price proxy\n",
    "    prices = (1 + returns).cumprod()\n",
    "    \n",
    "    # RSI-like indicator for each signal\n",
    "    for col in X.columns[:10]:  # Base signals only\n",
    "        # Calculate gains and losses\n",
    "        delta = X[col].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        \n",
    "        # RSI\n",
    "        rs = gain / (loss + 1e-10)\n",
    "        X_tech[f'{col}_rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Bands for signals\n",
    "    for col in X.columns[:5]:  # Top 5 signals\n",
    "        ma = X[col].rolling(window=20).mean()\n",
    "        std = X[col].rolling(window=20).std()\n",
    "        X_tech[f'{col}_bb_upper'] = ma + 2 * std\n",
    "        X_tech[f'{col}_bb_lower'] = ma - 2 * std\n",
    "        X_tech[f'{col}_bb_width'] = X_tech[f'{col}_bb_upper'] - X_tech[f'{col}_bb_lower']\n",
    "        X_tech[f'{col}_bb_position'] = (X[col] - X_tech[f'{col}_bb_lower']) / (X_tech[f'{col}_bb_width'] + 1e-10)\n",
    "    \n",
    "    # MACD-like indicators\n",
    "    for col in X.columns[:5]:\n",
    "        ema_12 = X[col].ewm(span=12, adjust=False).mean()\n",
    "        ema_26 = X[col].ewm(span=26, adjust=False).mean()\n",
    "        X_tech[f'{col}_macd'] = ema_12 - ema_26\n",
    "        X_tech[f'{col}_macd_signal'] = X_tech[f'{col}_macd'].ewm(span=9, adjust=False).mean()\n",
    "        X_tech[f'{col}_macd_hist'] = X_tech[f'{col}_macd'] - X_tech[f'{col}_macd_signal']\n",
    "    \n",
    "    # Stochastic oscillator\n",
    "    for col in X.columns[:3]:\n",
    "        low_14 = X[col].rolling(window=14).min()\n",
    "        high_14 = X[col].rolling(window=14).max()\n",
    "        X_tech[f'{col}_stoch'] = 100 * (X[col] - low_14) / (high_14 - low_14 + 1e-10)\n",
    "    \n",
    "    return X_tech\n",
    "\n",
    "# Create technical indicators\n",
    "print(\"Creating technical indicators...\")\n",
    "X_technical = create_technical_indicators(X_base, y)\n",
    "print(f\"Technical indicators created: {len(X_technical.columns)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all feature sets\n",
    "X_all = pd.concat([\n",
    "    X_temporal,\n",
    "    X_nonlinear,\n",
    "    X_technical\n",
    "], axis=1)\n",
    "\n",
    "# Remove duplicate columns if any\n",
    "X_all = X_all.loc[:, ~X_all.columns.duplicated()]\n",
    "\n",
    "# Handle missing values (from rolling windows)\n",
    "X_all = X_all.fillna(0)  # Simple fill with 0, could use forward fill or interpolation\n",
    "\n",
    "print(f\"\\nTotal features created: {len(X_all.columns)}\")\n",
    "print(f\"Shape before cleaning: {X_all.shape}\")\n",
    "\n",
    "# Remove features with zero variance\n",
    "variance = X_all.var()\n",
    "zero_var_features = variance[variance == 0].index.tolist()\n",
    "if zero_var_features:\n",
    "    print(f\"Removing {len(zero_var_features)} zero-variance features\")\n",
    "    X_all = X_all.drop(columns=zero_var_features)\n",
    "\n",
    "# Remove highly correlated features (correlation > 0.99)\n",
    "corr_matrix = X_all.corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.99)]\n",
    "if to_drop:\n",
    "    print(f\"Removing {len(to_drop)} highly correlated features\")\n",
    "    X_all = X_all.drop(columns=to_drop)\n",
    "\n",
    "print(f\"\\nFinal shape after cleaning: {X_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature selection (remove NaN rows from beginning)\n",
    "min_samples = 100  # Minimum samples needed\n",
    "first_valid_idx = X_all.index[X_all.notna().all(axis=1)].min()\n",
    "if first_valid_idx > min_samples:\n",
    "    first_valid_idx = min_samples\n",
    "\n",
    "X_selection = X_all.iloc[first_valid_idx:].copy()\n",
    "y_selection = y.iloc[first_valid_idx:].copy()\n",
    "\n",
    "print(f\"Data for feature selection: {X_selection.shape}\")\n",
    "\n",
    "# Method 1: Mutual Information\n",
    "print(\"\\n1. Mutual Information Feature Selection\")\n",
    "mi_scores = mutual_info_regression(X_selection, y_selection, random_state=42)\n",
    "mi_scores = pd.Series(mi_scores, index=X_selection.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot top features by MI\n",
    "plt.figure(figsize=(12, 6))\n",
    "mi_scores.head(30).plot(kind='barh')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.title('Top 30 Features by Mutual Information')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top 10 features by MI:\")\n",
    "for i, (feat, score) in enumerate(mi_scores.head(10).items(), 1):\n",
    "    print(f\"  {i}. {feat}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Random Forest Feature Importance\n",
    "print(\"\\n2. Random Forest Feature Importance\")\n",
    "\n",
    "# Train a simple RF model\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_selection, y_selection)\n",
    "\n",
    "# Get feature importances\n",
    "rf_importance = pd.Series(rf.feature_importances_, index=X_selection.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot top features\n",
    "plt.figure(figsize=(12, 6))\n",
    "rf_importance.head(30).plot(kind='barh')\n",
    "plt.xlabel('Random Forest Feature Importance')\n",
    "plt.title('Top 30 Features by Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top 10 features by RF:\")\n",
    "for i, (feat, score) in enumerate(rf_importance.head(10).items(), 1):\n",
    "    print(f\"  {i}. {feat}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Recursive Feature Elimination\n",
    "print(\"\\n3. Recursive Feature Elimination (selecting top 50 features)\")\n",
    "\n",
    "# Use a simple model for RFE\n",
    "from sklearn.linear_model import Ridge\n",
    "estimator = Ridge(alpha=1.0)\n",
    "\n",
    "# RFE to select top 50 features\n",
    "n_features_to_select = min(50, X_selection.shape[1] // 2)\n",
    "rfe = RFE(estimator, n_features_to_select=n_features_to_select, step=10)\n",
    "rfe.fit(X_selection, y_selection)\n",
    "\n",
    "# Get selected features\n",
    "rfe_selected = X_selection.columns[rfe.support_].tolist()\n",
    "print(f\"Selected {len(rfe_selected)} features by RFE\")\n",
    "print(f\"Sample of selected features: {rfe_selected[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Final Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different feature sets for model comparison\n",
    "\n",
    "# Set 1: Base features only\n",
    "feature_set_base = X_base.columns.tolist()\n",
    "\n",
    "# Set 2: Base + top temporal features\n",
    "temporal_cols = [col for col in X_all.columns if any(x in col for x in ['lag', 'roll', 'momentum'])]\n",
    "top_temporal = [col for col in mi_scores.head(100).index if col in temporal_cols][:20]\n",
    "feature_set_temporal = feature_set_base + top_temporal\n",
    "\n",
    "# Set 3: Top 50 by mutual information\n",
    "feature_set_mi = mi_scores.head(50).index.tolist()\n",
    "\n",
    "# Set 4: Top 50 by random forest\n",
    "feature_set_rf = rf_importance.head(50).index.tolist()\n",
    "\n",
    "# Set 5: RFE selected features\n",
    "feature_set_rfe = rfe_selected\n",
    "\n",
    "# Set 6: Union of top features from all methods\n",
    "feature_set_union = list(set(\n",
    "    mi_scores.head(30).index.tolist() + \n",
    "    rf_importance.head(30).index.tolist() + \n",
    "    rfe_selected[:30]\n",
    "))\n",
    "\n",
    "# Set 7: All features (for neural networks)\n",
    "feature_set_all = X_all.columns.tolist()\n",
    "\n",
    "print(\"Feature sets created:\")\n",
    "print(f\"  1. Base: {len(feature_set_base)} features\")\n",
    "print(f\"  2. Temporal: {len(feature_set_temporal)} features\")\n",
    "print(f\"  3. MI Top 50: {len(feature_set_mi)} features\")\n",
    "print(f\"  4. RF Top 50: {len(feature_set_rf)} features\")\n",
    "print(f\"  5. RFE Selected: {len(feature_set_rfe)} features\")\n",
    "print(f\"  6. Union: {len(feature_set_union)} features\")\n",
    "print(f\"  7. All: {len(feature_set_all)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all engineered features\n",
    "X_all.to_csv('./data/processed/engineered_features.csv', index=False)\n",
    "y.to_csv('./data/processed/aligned_targets.csv', index=False)\n",
    "\n",
    "# Save feature sets\n",
    "import json\n",
    "\n",
    "feature_sets = {\n",
    "    'base': feature_set_base,\n",
    "    'temporal': feature_set_temporal,\n",
    "    'mi_top50': feature_set_mi,\n",
    "    'rf_top50': feature_set_rf,\n",
    "    'rfe_selected': feature_set_rfe,\n",
    "    'union': feature_set_union,\n",
    "    'all': feature_set_all\n",
    "}\n",
    "\n",
    "with open('./data/processed/feature_sets.json', 'w') as f:\n",
    "    json.dump(feature_sets, f, indent=2)\n",
    "\n",
    "# Save feature importance scores\n",
    "feature_importance = pd.DataFrame({\n",
    "    'mutual_information': mi_scores,\n",
    "    'random_forest': rf_importance\n",
    "})\n",
    "feature_importance.to_csv('./data/processed/feature_importance.csv')\n",
    "\n",
    "print(\"\\n✓ Features saved successfully!\")\n",
    "print(f\"  - Engineered features: ./data/processed/engineered_features.csv\")\n",
    "print(f\"  - Aligned targets: ./data/processed/aligned_targets.csv\")\n",
    "print(f\"  - Feature sets: ./data/processed/feature_sets.json\")\n",
    "print(f\"  - Feature importance: ./data/processed/feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Total Features Created: {len(X_all.columns)}\n",
    "\n",
    "Feature Categories:\n",
    "  • Base Features: {len(feature_set_base)}\n",
    "  • Temporal Features: {len([c for c in X_all.columns if any(x in c for x in ['lag', 'roll', 'momentum', 'roc'])])}\n",
    "  • Non-linear Features: {len([c for c in X_all.columns if any(x in c for x in ['_x_', 'pow', 'div', 'sin', 'cos'])])}\n",
    "  • Technical Indicators: {len([c for c in X_all.columns if any(x in c for x in ['rsi', 'bb_', 'macd', 'stoch'])])}\n",
    "\n",
    "Feature Selection Results:\n",
    "  • Most important feature (MI): {mi_scores.index[0]} (score: {mi_scores.iloc[0]:.4f})\n",
    "  • Most important feature (RF): {rf_importance.index[0]} (score: {rf_importance.iloc[0]:.4f})\n",
    "  • Features selected by RFE: {len(rfe_selected)}\n",
    "\n",
    "Key Insights:\n",
    "  1. Temporal features (lags, rolling stats) show significant importance\n",
    "  2. Non-linear interactions capture complex patterns\n",
    "  3. Technical indicators add domain-specific signals\n",
    "  4. Feature selection identifies most predictive subset\n",
    "  5. Multiple feature sets created for model comparison\n",
    "\n",
    "Next Steps:\n",
    "  → Model development with different feature sets\n",
    "  → Cross-validation to assess generalization\n",
    "  → Ensemble methods to combine predictions\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quant_trade)",
   "language": "python",
   "name": "quant_trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
