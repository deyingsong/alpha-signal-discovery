{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Backtesting Trading Strategy\n",
    "## Realistic Trading Simulation with Transaction Costs\n",
    "\n",
    "This notebook implements comprehensive backtesting with:\n",
    "- Transaction cost modeling (50 bps)\n",
    "- Position sizing and risk management\n",
    "- Performance metrics calculation\n",
    "- Strategy optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "root_folder = './'  # Change this to your root folder path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_all = pd.read_csv(f'{root_folder}data/processed/engineered_features.csv')\n",
    "y = pd.read_csv(f'{root_folder}data/processed/aligned_targets.csv').squeeze()\n",
    "\n",
    "# Load best model info from CV\n",
    "with open(f'{root_folder}data/results/best_model_cv.json', 'r') as f:\n",
    "    best_model_info = json.load(f)\n",
    "\n",
    "print(f\"Best model from CV: {best_model_info['model_name']}\")\n",
    "print(f\"CV Performance:\")\n",
    "for metric, value in best_model_info['avg_metrics'].items():\n",
    "    print(f\"  {metric}: {value:.6f}\")\n",
    "\n",
    "# Load feature set\n",
    "feature_set = best_model_info['feature_set']\n",
    "X_selected = X_all[feature_set]\n",
    "\n",
    "# Transaction cost\n",
    "TRANSACTION_COST = 0.005  # 50 bps\n",
    "print(f\"\\nTransaction cost: {TRANSACTION_COST:.3f} ({TRANSACTION_COST*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for backtesting\n",
    "# Use last 30% for out-of-sample backtesting\n",
    "train_size = int(0.7 * len(X_selected))\n",
    "test_size = len(X_selected) - train_size\n",
    "\n",
    "X_train = X_selected.iloc[:train_size]\n",
    "X_test = X_selected.iloc[train_size:]\n",
    "y_train = y.iloc[:train_size]\n",
    "y_test = y.iloc[train_size:]\n",
    "\n",
    "print(f\"Training period: samples 0 to {train_size-1}\")\n",
    "print(f\"Testing period: samples {train_size} to {len(X_selected)-1}\")\n",
    "print(f\"Test set size: {test_size} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Final Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model on full training set\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Select and train model based on best from CV\n",
    "model_name = best_model_info['model_name']\n",
    "\n",
    "if model_name == 'Ridge':\n",
    "    model = Ridge(alpha=10.0, random_state=42)\n",
    "elif model_name == 'RandomForest':\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=200, max_depth=10, min_samples_split=10,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "elif model_name == 'XGBoost':\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=300, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=42, n_jobs=-1\n",
    "    )\n",
    "elif model_name == 'LightGBM':\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=300, max_depth=5, learning_rate=0.05,\n",
    "        random_state=42, n_jobs=-1, verbose=-1\n",
    "    )\n",
    "\n",
    "print(f\"Training {model_name} model...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "train_predictions = model.predict(X_train_scaled)\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Model trained. Generating predictions for backtesting...\")\n",
    "print(f\"Prediction statistics:\")\n",
    "print(f\"  Train - Mean: {np.mean(train_predictions):.6f}, Std: {np.std(train_predictions):.6f}\")\n",
    "print(f\"  Test - Mean: {np.mean(test_predictions):.6f}, Std: {np.std(test_predictions):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Backtesting Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingBacktester:\n",
    "    \"\"\"Complete backtesting engine with transaction costs.\"\"\"\n",
    "    \n",
    "    def __init__(self, transaction_cost=0.005):\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "    def generate_signals(self, predictions, threshold=0.0, signal_type='threshold'):\n",
    "        \"\"\"Generate trading signals from predictions.\"\"\"\n",
    "        \n",
    "        if signal_type == 'threshold':\n",
    "            # Threshold-based signals\n",
    "            signals = np.where(predictions > threshold, 1,\n",
    "                             np.where(predictions < -threshold, -1, 0))\n",
    "        \n",
    "        elif signal_type == 'percentile':\n",
    "            # Percentile-based signals\n",
    "            upper = np.percentile(predictions, 100 - threshold)\n",
    "            lower = np.percentile(predictions, threshold)\n",
    "            signals = np.where(predictions > upper, 1,\n",
    "                             np.where(predictions < lower, -1, 0))\n",
    "        \n",
    "        elif signal_type == 'zscore':\n",
    "            # Z-score based signals\n",
    "            z_scores = (predictions - np.mean(predictions)) / np.std(predictions)\n",
    "            signals = np.where(z_scores > threshold, 1,\n",
    "                             np.where(z_scores < -threshold, -1, 0))\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def calculate_returns(self, signals, actual_returns):\n",
    "        \"\"\"Calculate strategy returns including transaction costs.\"\"\"\n",
    "        \n",
    "        # Calculate position changes\n",
    "        positions = signals.copy()\n",
    "        position_changes = np.diff(np.concatenate([[0], positions]))\n",
    "        \n",
    "        # Calculate transaction costs\n",
    "        transaction_costs = np.abs(position_changes) * self.transaction_cost\n",
    "        \n",
    "        # Calculate gross and net returns\n",
    "        gross_returns = positions * actual_returns\n",
    "        net_returns = gross_returns - transaction_costs\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results = pd.DataFrame({\n",
    "            'signal': signals,\n",
    "            'position': positions,\n",
    "            'position_change': position_changes,\n",
    "            'actual_return': actual_returns,\n",
    "            'gross_return': gross_returns,\n",
    "            'transaction_cost': transaction_costs,\n",
    "            'net_return': net_returns,\n",
    "            'cumulative_return': (1 + net_returns).cumprod() - 1\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calculate_metrics(self, returns):\n",
    "        \"\"\"Calculate performance metrics.\"\"\"\n",
    "        \n",
    "        # Filter out any NaN values\n",
    "        returns = returns[~np.isnan(returns)]\n",
    "        \n",
    "        # Basic metrics\n",
    "        total_return = (1 + returns).prod() - 1\n",
    "        n_periods = len(returns)\n",
    "        annualized_return = (1 + total_return) ** (252 / n_periods) - 1\n",
    "        annualized_vol = np.std(returns) * np.sqrt(252)\n",
    "        \n",
    "        # Risk-adjusted metrics\n",
    "        sharpe_ratio = annualized_return / annualized_vol if annualized_vol > 0 else 0\n",
    "        \n",
    "        # Downside metrics\n",
    "        downside_returns = returns[returns < 0]\n",
    "        if len(downside_returns) > 0:\n",
    "            downside_vol = np.std(downside_returns) * np.sqrt(252)\n",
    "            sortino_ratio = annualized_return / downside_vol if downside_vol > 0 else 0\n",
    "        else:\n",
    "            sortino_ratio = np.inf\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative = (1 + returns).cumprod()\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_max) / running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Calmar ratio\n",
    "        calmar_ratio = annualized_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "        \n",
    "        # Win rate\n",
    "        win_rate = np.mean(returns > 0)\n",
    "        \n",
    "        # Average win/loss\n",
    "        winning_returns = returns[returns > 0]\n",
    "        losing_returns = returns[returns < 0]\n",
    "        avg_win = np.mean(winning_returns) if len(winning_returns) > 0 else 0\n",
    "        avg_loss = np.mean(losing_returns) if len(losing_returns) > 0 else 0\n",
    "        \n",
    "        # Profit factor\n",
    "        total_wins = np.sum(winning_returns) if len(winning_returns) > 0 else 0\n",
    "        total_losses = abs(np.sum(losing_returns)) if len(losing_returns) > 0 else 1e-10\n",
    "        profit_factor = total_wins / total_losses\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'annualized_return': annualized_return,\n",
    "            'annualized_volatility': annualized_vol,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'sortino_ratio': sortino_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'calmar_ratio': calmar_ratio,\n",
    "            'win_rate': win_rate,\n",
    "            'avg_win': avg_win,\n",
    "            'avg_loss': avg_loss,\n",
    "            'profit_factor': profit_factor,\n",
    "            'num_trades': np.sum(np.abs(np.diff(returns != 0)))\n",
    "        }\n",
    "\n",
    "# Initialize backtester\n",
    "backtester = TradingBacktester(transaction_cost=TRANSACTION_COST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize threshold on training data\n",
    "def optimize_threshold(predictions, returns, backtester, threshold_range=None):\n",
    "    \"\"\"Find optimal threshold for signal generation.\"\"\"\n",
    "    \n",
    "    if threshold_range is None:\n",
    "        # Use percentiles of absolute predictions\n",
    "        threshold_range = np.percentile(np.abs(predictions), np.linspace(0, 95, 50))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for threshold in threshold_range:\n",
    "        signals = backtester.generate_signals(predictions, threshold, 'threshold')\n",
    "        backtest_results = backtester.calculate_returns(signals, returns)\n",
    "        metrics = backtester.calculate_metrics(backtest_results['net_return'])\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'sharpe_ratio': metrics['sharpe_ratio'],\n",
    "            'total_return': metrics['total_return'],\n",
    "            'max_drawdown': metrics['max_drawdown'],\n",
    "            'num_trades': metrics['num_trades']\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Find optimal threshold (maximize Sharpe ratio)\n",
    "    optimal_idx = results_df['sharpe_ratio'].idxmax()\n",
    "    optimal_threshold = results_df.loc[optimal_idx, 'threshold']\n",
    "    \n",
    "    return optimal_threshold, results_df\n",
    "\n",
    "# Optimize on training data\n",
    "print(\"Optimizing trading threshold on training data...\")\n",
    "optimal_threshold, threshold_results = optimize_threshold(\n",
    "    train_predictions, y_train.values, backtester\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimal threshold: {optimal_threshold:.6f}\")\n",
    "print(f\"Training performance at optimal threshold:\")\n",
    "optimal_row = threshold_results[threshold_results['threshold'] == optimal_threshold].iloc[0]\n",
    "for col, val in optimal_row.items():\n",
    "    if col != 'threshold':\n",
    "        print(f\"  {col}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize threshold optimization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Sharpe ratio vs threshold\n",
    "axes[0, 0].plot(threshold_results['threshold'], threshold_results['sharpe_ratio'], 'b-', linewidth=2)\n",
    "axes[0, 0].axvline(x=optimal_threshold, color='red', linestyle='--', alpha=0.7, label=f'Optimal: {optimal_threshold:.4f}')\n",
    "axes[0, 0].set_xlabel('Threshold')\n",
    "axes[0, 0].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 0].set_title('Sharpe Ratio vs Threshold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Total return vs threshold\n",
    "axes[0, 1].plot(threshold_results['threshold'], threshold_results['total_return'], 'g-', linewidth=2)\n",
    "axes[0, 1].axvline(x=optimal_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Threshold')\n",
    "axes[0, 1].set_ylabel('Total Return')\n",
    "axes[0, 1].set_title('Total Return vs Threshold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Max drawdown vs threshold\n",
    "axes[1, 0].plot(threshold_results['threshold'], threshold_results['max_drawdown'], 'r-', linewidth=2)\n",
    "axes[1, 0].axvline(x=optimal_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Threshold')\n",
    "axes[1, 0].set_ylabel('Max Drawdown')\n",
    "axes[1, 0].set_title('Maximum Drawdown vs Threshold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Number of trades vs threshold\n",
    "axes[1, 1].plot(threshold_results['threshold'], threshold_results['num_trades'], 'm-', linewidth=2)\n",
    "axes[1, 1].axvline(x=optimal_threshold, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Threshold')\n",
    "axes[1, 1].set_ylabel('Number of Trades')\n",
    "axes[1, 1].set_title('Trading Frequency vs Threshold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Threshold Optimization Results (Training Data)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Out-of-Sample Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest on test data with optimal threshold\n",
    "print(\"Running out-of-sample backtest...\")\n",
    "print(f\"Using threshold: {optimal_threshold:.6f}\\n\")\n",
    "\n",
    "# Generate signals\n",
    "test_signals = backtester.generate_signals(test_predictions, optimal_threshold, 'threshold')\n",
    "\n",
    "# Calculate returns\n",
    "test_backtest = backtester.calculate_returns(test_signals, y_test.values)\n",
    "\n",
    "# Calculate metrics\n",
    "test_metrics = backtester.calculate_metrics(test_backtest['net_return'])\n",
    "\n",
    "# Display results\n",
    "print(\"Out-of-Sample Performance Metrics:\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in test_metrics.items():\n",
    "    if 'return' in metric or 'ratio' in metric or 'drawdown' in metric:\n",
    "        print(f\"{metric:25s}: {value:12.4f}\")\n",
    "    else:\n",
    "        print(f\"{metric:25s}: {value:12.4f}\")\n",
    "\n",
    "# Compare with buy-and-hold\n",
    "buy_hold_return = (1 + y_test).prod() - 1\n",
    "buy_hold_annual = (1 + buy_hold_return) ** (252 / len(y_test)) - 1\n",
    "buy_hold_sharpe = buy_hold_annual / (np.std(y_test) * np.sqrt(252))\n",
    "\n",
    "print(\"\\nBuy-and-Hold Benchmark:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Total Return':25s}: {buy_hold_return:12.4f}\")\n",
    "print(f\"{'Annualized Return':25s}: {buy_hold_annual:12.4f}\")\n",
    "print(f\"{'Sharpe Ratio':25s}: {buy_hold_sharpe:12.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "print(\"\\nStrategy vs Buy-and-Hold:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Return Difference: {test_metrics['total_return'] - buy_hold_return:.4f}\")\n",
    "print(f\"Sharpe Improvement: {test_metrics['sharpe_ratio'] - buy_hold_sharpe:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance visualization\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Cumulative Returns\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "strategy_cumulative = (1 + test_backtest['net_return']).cumprod()\n",
    "buyhold_cumulative = (1 + y_test).cumprod()\n",
    "\n",
    "ax1.plot(strategy_cumulative.values, label='Strategy', linewidth=2, color='blue')\n",
    "ax1.plot(buyhold_cumulative.values, label='Buy & Hold', linewidth=2, color='gray', alpha=0.7)\n",
    "ax1.set_title('Cumulative Returns Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Time Period')\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Drawdown\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "running_max = strategy_cumulative.expanding().max()\n",
    "drawdown = (strategy_cumulative - running_max) / running_max * 100\n",
    "\n",
    "ax2.fill_between(range(len(drawdown)), drawdown.values, 0, color='red', alpha=0.3)\n",
    "ax2.plot(drawdown.values, color='red', linewidth=1)\n",
    "ax2.set_title('Strategy Drawdown', fontsize=12)\n",
    "ax2.set_xlabel('Time Period')\n",
    "ax2.set_ylabel('Drawdown (%)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Rolling Sharpe Ratio (60-day)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "rolling_returns = pd.Series(test_backtest['net_return'].values)\n",
    "rolling_sharpe = (rolling_returns.rolling(60).mean() / rolling_returns.rolling(60).std()) * np.sqrt(252)\n",
    "\n",
    "ax3.plot(rolling_sharpe.values, color='green', linewidth=1)\n",
    "ax3.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(y=test_metrics['sharpe_ratio'], color='blue', linestyle='--', alpha=0.5, label=f\"Avg: {test_metrics['sharpe_ratio']:.2f}\")\n",
    "ax3.set_title('Rolling 60-Day Sharpe Ratio', fontsize=12)\n",
    "ax3.set_xlabel('Time Period')\n",
    "ax3.set_ylabel('Sharpe Ratio')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Position Distribution\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "position_counts = pd.Series(test_signals).value_counts()\n",
    "colors = ['red' if x == -1 else 'green' if x == 1 else 'gray' for x in position_counts.index]\n",
    "ax4.bar(position_counts.index, position_counts.values, color=colors, alpha=0.7)\n",
    "ax4.set_title('Position Distribution', fontsize=12)\n",
    "ax4.set_xlabel('Position (-1: Short, 0: Flat, 1: Long)')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_xticks([-1, 0, 1])\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Monthly Returns Heatmap\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "\n",
    "# Create monthly returns\n",
    "test_dates = pd.date_range(start='2020-01-01', periods=len(test_backtest), freq='D')\n",
    "returns_series = pd.Series(test_backtest['net_return'].values, index=test_dates)\n",
    "monthly_returns = returns_series.groupby([returns_series.index.year, returns_series.index.month]).apply(lambda x: (1 + x).prod() - 1)\n",
    "\n",
    "# Reshape for heatmap\n",
    "if len(monthly_returns) > 0:\n",
    "    monthly_pivot = monthly_returns.unstack(level=1)\n",
    "    monthly_pivot.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(monthly_pivot * 100, annot=True, fmt='.1f', cmap='RdYlGn', center=0, \n",
    "                cbar_kws={'label': 'Return (%)'}, ax=ax5, vmin=-10, vmax=10)\n",
    "    ax5.set_title('Monthly Returns Heatmap (%)', fontsize=12)\n",
    "    ax5.set_xlabel('Month')\n",
    "    ax5.set_ylabel('Year')\n",
    "\n",
    "plt.suptitle('Trading Strategy Performance Analysis', fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk analysis\n",
    "returns = test_backtest['net_return'].values\n",
    "\n",
    "# Value at Risk (VaR)\n",
    "confidence_levels = [0.95, 0.99]\n",
    "vars = {}\n",
    "cvars = {}\n",
    "\n",
    "for conf in confidence_levels:\n",
    "    var = np.percentile(returns, (1 - conf) * 100)\n",
    "    cvar = returns[returns <= var].mean()\n",
    "    vars[conf] = var\n",
    "    cvars[conf] = cvar\n",
    "\n",
    "print(\"Risk Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nValue at Risk (VaR):\")\n",
    "for conf in confidence_levels:\n",
    "    print(f\"  {conf*100:.0f}% VaR: {vars[conf]:.4f} ({vars[conf]*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nConditional Value at Risk (CVaR):\")\n",
    "for conf in confidence_levels:\n",
    "    print(f\"  {conf*100:.0f}% CVaR: {cvars[conf]:.4f} ({cvars[conf]*100:.2f}%)\")\n",
    "\n",
    "# Risk-adjusted returns\n",
    "print(\"\\nRisk-Adjusted Performance:\")\n",
    "print(f\"  Information Ratio: {test_metrics['annualized_return'] / np.std(returns - y_test.mean()):.4f}\")\n",
    "print(f\"  Omega Ratio: {np.sum(returns[returns > 0]) / abs(np.sum(returns[returns < 0])):.4f}\")\n",
    "\n",
    "# Tail ratio\n",
    "right_tail = np.percentile(returns, 95)\n",
    "left_tail = abs(np.percentile(returns, 5))\n",
    "tail_ratio = right_tail / left_tail if left_tail != 0 else np.inf\n",
    "print(f\"  Tail Ratio (95/5): {tail_ratio:.4f}\")\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "print(\"\\nDistribution Properties:\")\n",
    "print(f\"  Skewness: {stats.skew(returns):.4f}\")\n",
    "print(f\"  Kurtosis: {stats.kurtosis(returns):.4f}\")\n",
    "\n",
    "# Stability metrics\n",
    "rolling_vol = pd.Series(returns).rolling(30).std() * np.sqrt(252)\n",
    "print(f\"\\nVolatility Statistics:\")\n",
    "print(f\"  Min 30-day Vol: {rolling_vol.min():.4f}\")\n",
    "print(f\"  Max 30-day Vol: {rolling_vol.max():.4f}\")\n",
    "print(f\"  Vol of Vol: {rolling_vol.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Transaction Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze impact of transaction costs\n",
    "transaction_costs = test_backtest['transaction_cost'].values\n",
    "gross_returns = test_backtest['gross_return'].values\n",
    "net_returns = test_backtest['net_return'].values\n",
    "\n",
    "# Calculate cost impact\n",
    "total_transaction_costs = np.sum(transaction_costs)\n",
    "gross_total_return = (1 + gross_returns).prod() - 1\n",
    "net_total_return = (1 + net_returns).prod() - 1\n",
    "cost_drag = gross_total_return - net_total_return\n",
    "\n",
    "# Trading statistics\n",
    "n_trades = np.sum(test_backtest['position_change'] != 0)\n",
    "avg_cost_per_trade = total_transaction_costs / n_trades if n_trades > 0 else 0\n",
    "\n",
    "print(\"Transaction Cost Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Transaction Costs: {total_transaction_costs:.4f} ({total_transaction_costs*100:.2f}%)\")\n",
    "print(f\"Number of Trades: {n_trades}\")\n",
    "print(f\"Average Cost per Trade: {avg_cost_per_trade:.4f} ({avg_cost_per_trade*100:.2f}%)\")\n",
    "print(f\"\\nReturn Impact:\")\n",
    "print(f\"  Gross Total Return: {gross_total_return:.4f} ({gross_total_return*100:.2f}%)\")\n",
    "print(f\"  Net Total Return: {net_total_return:.4f} ({net_total_return*100:.2f}%)\")\n",
    "print(f\"  Cost Drag: {cost_drag:.4f} ({cost_drag*100:.2f}%)\")\n",
    "print(f\"\\nBreak-even Win Rate: {TRANSACTION_COST / (2 * np.mean(np.abs(y_test))):.2%}\")\n",
    "\n",
    "# Sensitivity analysis\n",
    "cost_levels = np.array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.010])\n",
    "sensitivity_results = []\n",
    "\n",
    "for cost in cost_levels:\n",
    "    temp_backtester = TradingBacktester(transaction_cost=cost)\n",
    "    temp_results = temp_backtester.calculate_returns(test_signals, y_test.values)\n",
    "    temp_metrics = temp_backtester.calculate_metrics(temp_results['net_return'])\n",
    "    \n",
    "    sensitivity_results.append({\n",
    "        'cost_bps': cost * 10000,\n",
    "        'total_return': temp_metrics['total_return'],\n",
    "        'sharpe_ratio': temp_metrics['sharpe_ratio']\n",
    "    })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "\n",
    "# Plot sensitivity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].plot(sensitivity_df['cost_bps'], sensitivity_df['total_return'], 'b-', linewidth=2, marker='o')\n",
    "axes[0].axvline(x=TRANSACTION_COST*10000, color='red', linestyle='--', alpha=0.7, label='Current Cost')\n",
    "axes[0].axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "axes[0].set_xlabel('Transaction Cost (bps)')\n",
    "axes[0].set_ylabel('Total Return')\n",
    "axes[0].set_title('Return Sensitivity to Transaction Costs')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(sensitivity_df['cost_bps'], sensitivity_df['sharpe_ratio'], 'g-', linewidth=2, marker='o')\n",
    "axes[1].axvline(x=TRANSACTION_COST*10000, color='red', linestyle='--', alpha=0.7, label='Current Cost')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "axes[1].set_xlabel('Transaction Cost (bps)')\n",
    "axes[1].set_ylabel('Sharpe Ratio')\n",
    "axes[1].set_title('Sharpe Ratio Sensitivity to Transaction Costs')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Transaction Cost Sensitivity Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Backtest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "backtest_summary = {\n",
    "    'model': model_name,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'transaction_cost': TRANSACTION_COST,\n",
    "    'test_metrics': test_metrics,\n",
    "    'benchmark_metrics': {\n",
    "        'total_return': buy_hold_return,\n",
    "        'annualized_return': buy_hold_annual,\n",
    "        'sharpe_ratio': buy_hold_sharpe\n",
    "    },\n",
    "    'cost_analysis': {\n",
    "        'total_costs': total_transaction_costs,\n",
    "        'num_trades': n_trades,\n",
    "        'cost_drag': cost_drag\n",
    "    },\n",
    "    'risk_metrics': {\n",
    "        'var_95': vars[0.95],\n",
    "        'var_99': vars[0.99],\n",
    "        'cvar_95': cvars[0.95],\n",
    "        'cvar_99': cvars[0.99]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open(f'{root_folder}data/results/backtest_summary.json', 'w') as f:\n",
    "    json.dump(backtest_summary, f, indent=2, default=float)\n",
    "print(\"✓ Saved backtest summary\")\n",
    "\n",
    "# Save detailed results\n",
    "test_backtest.to_csv(f'{root_folder}data/results/backtest_details.csv', index=False)\n",
    "print(\"✓ Saved detailed backtest results\")\n",
    "\n",
    "# Save sensitivity analysis\n",
    "sensitivity_df.to_csv(f'{root_folder}data/results/cost_sensitivity.csv', index=False)\n",
    "print(\"✓ Saved cost sensitivity analysis\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BACKTEST COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Out-of-Sample Sharpe Ratio: {test_metrics['sharpe_ratio']:.4f}\")\n",
    "print(f\"Out-of-Sample Total Return: {test_metrics['total_return']:.4f}\")\n",
    "print(f\"Maximum Drawdown: {test_metrics['max_drawdown']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quant_trade)",
   "language": "python",
   "name": "quant_trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
